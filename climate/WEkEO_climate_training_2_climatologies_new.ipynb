{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/LogoWekeo_Copernicus_RGB_0.png' align='right' width='20%'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial on climatologies and trends\n",
    "In this tutorial we will use the WEkEO Jupyterhub to access and analyse data from the Climate Data Store (CDS) of the Copernicus Climate Change Service (C3S). The tutorial comprises the following steps:\n",
    "\n",
    "1. [Search and download](#search_download) data using the CDS API: We will focus on ERA5 reanalysis data of 2 metre (near-surface) temperature.\n",
    "2. [Read data](#read_data): Once downloaded, we will read and understand the data, including its variables and coordinates.\n",
    "3. [View and plot data](#view_plot): We will see how the mean temperature varies globally, and how the Earth is warming by plotting time-series of global anomalies.\n",
    "4. [Analyse data](#analyse_data) over the Arctic: We will focus on a subset over the Arctic and compare the rate of warming between seasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/map_1month_anomaly_Global_ea_2t_202010_title.jpg' align='center' width='100%'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='search_download'></a>1. Search and download data\n",
    "\n",
    "Before we begin we must prepare our environment. This includes installing the Application Programming Interface (API) of the CDS, and importing the various python libraries that we will need.\n",
    "\n",
    "#### Install CDS API\n",
    "\n",
    "To install the CDS API, run the following command. We use an exclamation mark to pass the command to the shell (not to the Python interpreter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cdsapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries\n",
    "\n",
    "We will be working with data in NetCDF format. To best handle this data we will use libraries for working with multidimensional arrays, in particular Xarray. We will also need libraries for plotting and viewing data, in this case we will use Matplotlib and Cartopy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CDS API\n",
    "import cdsapi\n",
    "\n",
    "# Libraries for working with multidimensional arrays\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "# Libraries for plotting and visualising data\n",
    "import matplotlib.path as mpath\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from zipfile import ZipFile\n",
    "import time\n",
    "import base64\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='read_data'></a> Select Option 1 (WEkEO API) or Option 2 (CDS API)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='read_data'></a> Option 1 WEkEO API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the API request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each dataset on WEkEO is assigned a unique `datasetId`. Let us store the dataset ID for `ERA5 monthly averaged data on single levels from 1979 to present` as a variable called `dataset_id` to be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"EO:ECMWF:DAT:REANALYSIS_ERA5_SINGLE_LEVELS_MONTHLY_MEANS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the WEkEO API key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to interact with WEkEO's Harmonised Data Access API, each user gets assigned an `API key` and `API token`. You will need the API key in order to download data in a programmatic way.\n",
    "\n",
    "The `api key` is generated by encoding your `username` and `password` to Base64. You can use the function [generate_api_key](./hda_api_functions.ipynb#generate_api_key) to programmatically generate your Base64-encoded api key. For this, you have to replace the 'username' and 'password' strings with your WEkEO username and password in the cell below.\n",
    "\n",
    "Alternatively, you can go to this [website](https://www.base64encode.org/) that allows you to manually encode your `username:password` combination. An example of an encoded key is `wekeo-test:wekeo-test`, which is encoded to `d2VrZW8tdGVzdDp3ZWtlby10ZXN0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDA API tools\n",
    "sys.path.append('./../wekeo-hda')\n",
    "from hda_api_functions import *\n",
    "\n",
    "user_name = 'USERNAME'\n",
    "password =  'PASSWORD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = generate_api_key(user_name, password)\n",
    "api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialise the Harmonised Data Access (HDA) API request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to initialise an API request, you have to initialise a dictionary that contains information on `dataset_id`, `api_key` and `download_directory_path`.\n",
    "\n",
    "Please enter the path of the directory where the data shall be downloaded to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter here the directory path where you want to download the data to\n",
    "download_dir_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `dataset_id`, `api_key` and `download_dir_path`, you can initialise the dictionary with the function [init](./hda_api_functions.ipynb#init)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hda_dict = init(dataset_id, api_key, download_dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Request access token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once initialised, you can request an access token with the function [get_access_token](./hda_api_functions.ipynb#get_access_token). The access token is stored in the `hda_dict` dictionary.\n",
    "\n",
    "You might need to accept the Terms and Conditions, which you can do with the function [acceptTandC](./hda_api_functions.ipynb#acceptTandC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hda_dict = get_access_token(hda_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accept Terms and Conditions (if applicable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hda_dict = acceptTandC(hda_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data descriptor file and request data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Harmonised Data Access API can read your data request from a dictionary. In this dictionary, you can describe the dataset you are interested in downloading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "  \"datasetId\": \"EO:ECMWF:DAT:REANALYSIS_ERA5_SINGLE_LEVELS_MONTHLY_MEANS\",\n",
    "  \"boundingBoxValues\": [\n",
    "    {\n",
    "      \"name\": \"area\",\n",
    "      \"bbox\": [\n",
    "        -180,\n",
    "        -90,\n",
    "        180,\n",
    "        90\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"stringChoiceValues\": [\n",
    "    {\n",
    "      \"name\": \"format\",\n",
    "      \"value\": \"netcdf\"\n",
    "    }\n",
    "  ],\n",
    "  \"multiStringSelectValues\": [\n",
    "    {\n",
    "      \"name\": \"time\",\n",
    "      \"value\": [\n",
    "        \"00:00\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"day\",\n",
    "      \"value\": [\n",
    "        \"01\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"month\",\n",
    "      \"value\": [\n",
    "        \"10\",\n",
    "        \"11\",\n",
    "        \"12\",\n",
    "        \"01\",\n",
    "        \"02\",\n",
    "        \"03\",\n",
    "        \"09\",\n",
    "        \"06\",\n",
    "        \"05\",\n",
    "        \"08\",\n",
    "        \"07\",\n",
    "        \"04\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"product_type\",\n",
    "      \"value\": [\n",
    "        \"monthly_averaged_reanalysis\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"variable\",\n",
    "      \"value\": [\n",
    "        \"2m_temperature\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"year\",\n",
    "      \"value\": [\n",
    "        \"1979\",\n",
    "        \"1980\",\n",
    "        \"1981\",\n",
    "        \"1982\",\n",
    "        \"1983\",\n",
    "        \"1984\",\n",
    "        \"1985\",\n",
    "        \"1986\",\n",
    "        \"1987\",\n",
    "        \"1988\",\n",
    "        \"1989\",\n",
    "        \"1990\",\n",
    "        \"1991\",\n",
    "        \"1992\",\n",
    "        \"1993\",\n",
    "        \"1994\",\n",
    "        \"1995\",\n",
    "        \"1996\",\n",
    "        \"1997\",\n",
    "        \"1998\",\n",
    "        \"1999\",\n",
    "        \"2000\",\n",
    "        \"2001\",\n",
    "        \"2002\",\n",
    "        \"2003\",\n",
    "        \"2004\",\n",
    "        \"2005\",\n",
    "        \"2006\",\n",
    "        \"2007\",\n",
    "        \"2008\",\n",
    "        \"2009\",\n",
    "        \"2010\",\n",
    "        \"2011\",\n",
    "        \"2012\",\n",
    "        \"2013\",\n",
    "        \"2014\",\n",
    "        \"2015\",\n",
    "        \"2016\",\n",
    "        \"2017\",\n",
    "        \"2018\",\n",
    "        \"2019\"\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initiate the request by assigning a job ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function [get_job_id](./hda_api_functions.ipynb#get_job_id) will launch your data request and your request is assigned a `job ID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hda_dict = get_job_id(hda_dict,data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build list of file names to be ordered and downloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to gather a list of file names available, based on your assigned `job ID`. The function [get_results_list](./hda_api_functions.ipynb#get_results_list) creates the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hda_dict = get_results_list(hda_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an `order ID` for each file to be downloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create an `order ID` for each file name to be downloaded. You can use the function [get_order_ids](./hda_api_functions.ipynb#get_order_ids)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hda_dict = get_order_ids(hda_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download requested data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final step, you can use the function [download_data](./hda_api_functions.ipynb#download_data) to initialize the data download and to download each file that has been assigned an `order ID`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_data(hda_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='read_data'></a> Option 2 CDS API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enter your CDS API key\n",
    "\n",
    "Before you can request data from the CDS, you will need to register on the CDS website and obtain a User ID and API Key. In order to do so, please follow the steps at this link:\n",
    "https://cds.climate.copernicus.eu/api-how-to\n",
    "\n",
    "Once you have a User ID and API Key, please enter them in the fields below by replacing \"UID\" with your User ID, and API_KEY with your API Key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"url: https://cds.climate.copernicus.eu/api/v2\" > ~/.cdsapirc\n",
    "!echo \"key: UID:API_KEY\" >> ~/.cdsapirc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search for data\n",
    "\n",
    "To search for data, visit the CDS website: http://cds.climate.copernicus.eu\n",
    "Here you can search for ERA5 data using the search bar. The data we need for this tutorial is the ERA5 monthly averaged data on single levels from 1979 to present.\n",
    "\n",
    "<img src='./img/CDS.jpg' align='left' width='45%'></img> <img src='./img/CDS_ERA5.jpg' align='right' width='45%'></img> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having selected the correct dataset, we now need to specify what product type, variables, temporal and geographic coverage we are interested in. These can all be selected in the **\"Download data\"** tab. In this tab a form appears in which we will select the following parameters to download:\n",
    "\n",
    "- Product type: `Monthly averaged reanalysis`\n",
    "- Variable: `2m temperature`\n",
    "- Year: `1979 to 2019`\n",
    "- Month: `all`\n",
    "- Time: `00:00` (default)\n",
    "- Geographical area: `Whole available region` \n",
    "- Format: `NetCDF`\n",
    "\n",
    "<img src='./img/Notebook2_data.png' align='center' width='100%'></img>\n",
    "\n",
    "At the end of the download form, select **\"Show API request\"**. This will reveal a block of code, which you can simply copy and paste into a cell of your Jupyter Notebook (see cell below) ...\n",
    "\n",
    "#### Download data\n",
    "\n",
    "... having copied the API request into the cell below, running this will retrieve and download the data you requested into your local directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = cdsapi.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.retrieve(\n",
    "    'reanalysis-era5-single-levels-monthly-means',\n",
    "    {\n",
    "        'product_type': 'monthly_averaged_reanalysis',\n",
    "        'variable': '2m_temperature',\n",
    "        'year': [\n",
    "            '1979', '1980', '1981',\n",
    "            '1982', '1983', '1984',\n",
    "            '1985', '1986', '1987',\n",
    "            '1988', '1989', '1990',\n",
    "            '1991', '1992', '1993',\n",
    "            '1994', '1995', '1996',\n",
    "            '1997', '1998', '1999',\n",
    "            '2000', '2001', '2002',\n",
    "            '2003', '2004', '2005',\n",
    "            '2006', '2007', '2008',\n",
    "            '2009', '2010', '2011',\n",
    "            '2012', '2013', '2014',\n",
    "            '2015', '2016', '2017',\n",
    "            '2018', '2019',\n",
    "        ],\n",
    "        'month': [\n",
    "            '01', '02', '03',\n",
    "            '04', '05', '06',\n",
    "            '07', '08', '09',\n",
    "            '10', '11', '12',\n",
    "        ],\n",
    "        'time': '00:00',\n",
    "        'format': 'netcdf',\n",
    "    },\n",
    "    'era5_monthly_t2m.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='read_data'></a>2. Read Data\n",
    "\n",
    "Now that we have downloaded the data, we can start to play ...\n",
    "\n",
    "We have requested the data in NetCDF format. This is a commonly used format for array-oriented scientific data. \n",
    "\n",
    "To read and process this data we will make use of the Xarray library. Xarray is an open source project and Python package that makes working with labelled multi-dimensional arrays simple, efficient, and fun! We will read the data from our NetCDF file into an Xarray **\"dataset\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option WEkEO API\n",
    "t2m = 'adaptor.mars.internal-1620660966.2440398-21838-1-358b5373-8d57-4d0e-9cab-e2a69d22287d.nc'\n",
    "\n",
    "# Option CDS API (Comment Out)\n",
    "#t2m = 'era5_monthly_t2m.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Xarray Dataset\n",
    "ds = xr.open_dataset(t2m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can query our newly created Xarray dataset ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the dataset has one variable called **\"t2m\"**, which stands for \"2 metre temperature\", and three coordinates of **longitude**, **latitude** and **time**.\n",
    "\n",
    "While an Xarray **dataset** may contain multiple variables, an Xarray **data array** holds a single multi-dimensional variable and its coordinates. To make the processing of the **t2m** data easier, we convert in into an Xarray data array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Xarray Data Array\n",
    "da = ds['t2m']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='view_plot'></a>3. View and plot data\n",
    "\n",
    "Now the fun part begins! Once our data is in the right format, there is no limit to what we can do with it! For example we can finally visualise the data to see what information it can provide.\n",
    "\n",
    "#### View temporal mean for reference period\n",
    "\n",
    "We will begin by creating a variable with the yearly means. Then we will extract the mean value for each geographic latitude and longitude for the period from 1981 to 2010. We will use this as a **reference period** with which to calculate **anomalies**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a variable with the yearly means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_mean = da.groupby('time.year').mean('time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate mean temperature for a reference period of 1981 to 2010:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = yearly_mean.where((yearly_mean.year > 1980) & (yearly_mean.year < 2011), drop=True)\n",
    "ref_mean = ref.mean(dim=\"year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot this to see how the mean temperature for this period varies globally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_mean.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the strong latitude gradient, and cold regions such as the Tibetan Plateau, the Andes and Greenland.\n",
    "\n",
    "#### Plot global anomalies\n",
    "\n",
    "We will now plot a global time series of annual temperature anomalies, defined as deviations in temperature from the reference mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the global mean for the reference period (1981 to 2010), and for the annual data from 1979 to 2019:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global mean for reference period\n",
    "ref_global = ref_mean.mean([\"longitude\", \"latitude\"])\n",
    "\n",
    "# global mean for annual data\n",
    "yearly_mean_global = yearly_mean.mean([\"longitude\", \"latitude\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now derive the anomalies by subtracting the global mean for the reference period from the annual means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies_global = yearly_mean_global - ref_global"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the annual global temperature anomalies over time, to see if there are any trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dashed horizontal line to show where the reference temperature lies\n",
    "mean_line = xr.DataArray(0.0, coords=[('year', np.arange(1981,2010))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,5))\n",
    "ax = plt.subplot()\n",
    "ax.set_ylabel('t2m anomaly (Kelvin)')\n",
    "ax.set_xlabel('year')\n",
    "ax.plot(anomalies_global.year, anomalies_global, color='green', label='Global anomalies')\n",
    "ax.plot(mean_line.year, mean_line, color='red', linestyle='dashed', label='Mean anomaly 1981-2019')\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels)\n",
    "ax.set_title('Global anomalies of t2m from 1979 to 2019')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice a clear trend in global temperature!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='analyse_data'></a>4. Analyse data over the Arctic\n",
    "We will now focus our attention over the Arctic. Here we will repeat the analysis above for this subset area. In addition, we will compare variations in the mean temperature of different seasons throughout the time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot mean Arctic temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to create a subset for the Arctic Circle (above lat 66Â°33'N, or 66.55 in decimal degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arctic = da.where(da.latitude >= 66.55, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate mean 2 metre temperature in period 1979 to 2019:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arctic_mean_1979_to_2019 = arctic.mean(dim=\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot this data in a map projection that facilitates visualisation of the Arctic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the figure panel \n",
    "fig = plt.figure(figsize=(5,5))\n",
    "# create the map using the cartopy Orthographic projection, selecting the North Pole\n",
    "ax = plt.subplot(1,1,1, projection=ccrs.Orthographic(central_latitude=90.0))\n",
    "# add coastlines\n",
    "ax.coastlines()\n",
    "# compute a circle in axes coordinates, which we can use as a boundary for the map.\n",
    "theta = np.linspace(0, 2*np.pi, 100)\n",
    "center, radius = [0.5, 0.5], 0.5\n",
    "verts = np.vstack([np.sin(theta), np.cos(theta)]).T\n",
    "circle = mpath.Path(verts * radius + center)\n",
    "# set boundary\n",
    "ax.set_extent([-180,180, 66.55,90], crs=ccrs.PlateCarree())\n",
    "ax.set_boundary(circle, transform=ax.transAxes)\n",
    "# provide a title\n",
    "ax.set_title('Mean Arctic t2m for period 1979 to 2019')\n",
    "# plot t2m\n",
    "pp = plt.pcolormesh(arctic_mean_1979_to_2019.longitude, arctic_mean_1979_to_2019.latitude,\n",
    "                    arctic_mean_1979_to_2019, cmap='viridis', transform=ccrs.PlateCarree())\n",
    "# add colourbar\n",
    "cbar = plt.colorbar(pp)\n",
    "cbar.set_label(label='t2m (Kelvin)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot monthly time series\n",
    "Let's plot the monthly time series to see if we can identify any trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arctic_mean = arctic.mean([\"longitude\", \"latitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arctic_mean.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you identify any global warming? The strong seasonal variations are evident throughout each year, but it is difficult to see any clear long-term trends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot yearly time series\n",
    "Now let's plot a time series of yearly averages. By removing the seasonal variations, perhaps we can identify some long-term trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arctic_yearly_mean = arctic_mean.groupby('time.year').mean('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arctic_yearly_mean.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can clearly see a positive trend in warming throughout the time-series!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot seasonal time series\n",
    "\n",
    "It may be interesting to compare trends in the mean temperature of different seasons throughout the time series. Do they vary? Are some seasons more constant over time, while others fluctuate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rolling average of three months\n",
    "arctic_roll = arctic_mean.rolling(time=3, center=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAM = arctic_roll[3:-8:12] # MAM = March, April, May (Spring)\n",
    "JJA = arctic_roll[6:-5:12] # JJA = June, July, August (Summer)\n",
    "SON = arctic_roll[9:-2:12] # SON = September, October, November (Autumn)\n",
    "DJF = arctic_roll[12:-11:12] # DJF = December, January, February (Winter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = plt.subplot()\n",
    "ax.set_ylabel('t2m (Kelvin)')\n",
    "ax.set_xlabel('year')\n",
    "ax.plot(MAM.time, MAM, color='green', label='Spring')\n",
    "ax.plot(JJA.time, JJA, color='red', label='Summer')\n",
    "ax.plot(SON.time, SON, color='orange', label='Autumn')\n",
    "ax.plot(DJF.time, DJF, color='blue', label='Winter')\n",
    "ax.set_title('Arctic seasonal t2m mean')\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels, bbox_to_anchor=(1, 1), loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the difference in variability of seasonal mean t2m throughout the time series: mean summer temperatures are more constant than in other seasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img src='./img/all_partners_wekeo.png' align='left' alt='Logo EU Copernicus' width='100%'></img></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
